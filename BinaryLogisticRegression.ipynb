{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e86f54a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tudor/CS-Work/ML/P1/LogisticRegression/LogisticRegression/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Imports and Consts\n",
    "SEED = 42 # For determnistic testing\n",
    "import numpy as np\n",
    "from util import get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "69e82d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 8)\n"
     ]
    }
   ],
   "source": [
    "# Read data and construct data sets\n",
    "data = get_data()\n",
    "data = data[1:]\n",
    "data = data.astype(float)\n",
    "xs = data[:, :-1]\n",
    "ys = data[:, -1]\n",
    "print(xs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9da25f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize Data\n",
    "xs = xs / np.linalg.norm(xs, axis=0, keepdims=True)\n",
    "xs = (xs - np.mean(xs, axis=0)) / np.std(xs, axis=0)\n",
    "\n",
    "# Add column to account for const B value in training\n",
    "ones = [[1.0]] * len(xs)\n",
    "xs = np.append(xs, ones, axis=1)\n",
    "\n",
    "# Shuffle\n",
    "np.random.seed(42)\n",
    "idxs = np.random.permutation(len(xs))\n",
    "\n",
    "xs = xs[idxs]\n",
    "ys = ys[idxs]\n",
    "\n",
    "# Split Data\n",
    "x_train = xs[:614]\n",
    "y_train = ys[:614]\n",
    "x_dev = xs[614:691]\n",
    "y_dev = ys[614:691]\n",
    "x_test = xs[691:]\n",
    "y_test = ys[691:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "43c3b791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers\n",
    "\n",
    "def Pr(arr: np.ndarray, param: np.ndarray) -> np.ndarray:\n",
    "    z = arr @ param\n",
    "    z_clipped = np.clip(z, -500, +500)\n",
    "    return 1.0 / (1.0 + np.exp(-z_clipped))\n",
    "\n",
    "def construct_w(p: np.ndarray) -> np.ndarray:\n",
    "    return np.diag((1 - p) * p)\n",
    "\n",
    "def compute_delta(X: np.ndarray, diag: np.ndarray, Y: np.ndarray, p: np.ndarray) -> np.ndarray:\n",
    "    H = X.T @ diag @ X + 1e-2 * np.diag(np.ones(X.shape[1]))\n",
    "    B = X.T @ (Y-p)\n",
    "\n",
    "    # Speed up computation via decomposition\n",
    "    L = np.linalg.cholesky(H)\n",
    "    \n",
    "    # Solve first only with L\n",
    "    temp = np.linalg.solve(L, B)\n",
    "\n",
    "    # Return final solution by solving for temp with L.T\n",
    "    return np.linalg.solve(L.T, temp)\n",
    "\n",
    "def loglik(p, y):\n",
    "    ll = np.sum(y * np.log(p + 1e-15) + (1 - y) * (1 - np.log(p + 1e-15)))\n",
    "    return ll\n",
    "\n",
    "def scale_const(X, Y, p_old, theta, delta, alpha):\n",
    "    ll_old = loglik(p_old, Y)\n",
    "\n",
    "    while True:\n",
    "        p_new = Pr(X, theta + alpha * delta)\n",
    "        ll_new = loglik(p_new, Y)\n",
    "        if ll_new < ll_old:\n",
    "            alpha *= 0.5\n",
    "        if alpha < 1e-8:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1276efd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(2.5333546236961806)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model Training\n",
    "\n",
    "def newton_method(X, Y, iters=1000):\n",
    "    # Initialize Theta\n",
    "    np.random.seed(42)\n",
    "    theta = np.random.randn(xs.shape[1])\n",
    "\n",
    "    alpha = 1.0\n",
    "    for _ in range(iters):\n",
    "        # Calc Values\n",
    "        p = Pr(X, theta)\n",
    "        W = construct_w(p)\n",
    "        delta = compute_delta(X, W, Y, p)\n",
    "\n",
    "        # Prevent exploding step\n",
    "        alpha = scale_const(X, Y, p, theta, delta, alpha)\n",
    "\n",
    "        # If next step would lower LL\n",
    "        if alpha is None:\n",
    "            return theta\n",
    "        else:\n",
    "            # Apply Newton method\n",
    "            theta += alpha * delta\n",
    "    return theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d90643d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictor\n",
    "\n",
    "def log_regression(X, theta):\n",
    "    logits = X @ theta\n",
    "\n",
    "    # Calculate probability of a 1\n",
    "    probs = 1.0 / (1.0 + np.exp(logits))\n",
    "\n",
    "    # Round to get preds\n",
    "    return np.round(probs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LogisticRegression",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
