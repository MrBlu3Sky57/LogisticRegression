{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ef5bff27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and Consts\n",
    "SEED = 42\n",
    "import numpy as np\n",
    "from util import get_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae164654",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read data and construct data sets\n",
    "NAME = \"uciml/iris\"\n",
    "data = get_data(\"uciml/iris\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4444a6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[1:]\n",
    "xs = data[:, 1:-1]\n",
    "xs = xs.astype(float)\n",
    "ys = data[:, -1]\n",
    "stoi = {y: i for i, y in enumerate(list(set(ys)))}\n",
    "for i in range(ys.size):\n",
    "    ys[i] = stoi[ys[i]]\n",
    "ys = ys.astype(int)\n",
    "itos = {stoi[y]: y for y in stoi}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "47906abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle\n",
    "np.random.seed(SEED)\n",
    "idxs = np.random.permutation(len(xs))\n",
    "\n",
    "xs = xs[idxs]\n",
    "ys = ys[idxs]\n",
    "\n",
    "# Split Data\n",
    "x_train = xs[:120]\n",
    "y_train = ys[:120]\n",
    "x_test = xs[120:]\n",
    "y_test = ys[120:]\n",
    "\n",
    "# Normalizing data\n",
    "train_mean = np.mean(x_train, axis=0)\n",
    "train_std = np.std(x_train, axis=0) + 1e-12\n",
    "\n",
    "x_train = (x_train - train_mean) / train_std\n",
    "x_test = (x_test - train_mean) / train_std\n",
    "\n",
    "# Extra column for bias term\n",
    "x_train = np.hstack([x_train, np.ones((len(x_train), 1)) ])\n",
    "x_test = np.hstack([ x_test, np.ones((len(x_test), 1)) ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2b5ce8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full Probability Matrix\n",
    "def Pr(X, theta):\n",
    "    \"\"\" \n",
    "    X: (n, d)\n",
    "    theta: (d, c)\n",
    "    \"\"\"\n",
    "    logits = X @ theta\n",
    "    logits = np.hstack([logits, np.zeros((X.shape[0], 1))]) # Add Last class\n",
    "    logits -= logits.max(axis=1, keepdims=True)\n",
    "    # logits = np.clip(logits, -500, 500)\n",
    "    exp = np.exp(logits)\n",
    "    row_sums = np.sum(exp, axis=1, keepdims=True)\n",
    "    return exp / row_sums\n",
    "\n",
    "# One Hot Encoding\n",
    "def one_hot(Y, d=3):\n",
    "    \"\"\"\n",
    "    Y: (n) -> (n, d) \n",
    "    \"\"\"\n",
    "    Y_oh = np.zeros(shape=(len(Y), d), dtype=np.int64)\n",
    "    idxs = np.arange(start=0, stop=len(Y), step=1)\n",
    "    Y_oh[idxs, Y] = 1\n",
    "    return Y_oh \n",
    "\n",
    "def jacobian(X, y_onehot, P):\n",
    "    total = X.T @ (y_onehot - P)\n",
    "    return total[:, :-1]\n",
    "\n",
    "theta = np.random.randn(5, 2)\n",
    "P = Pr(x_train, theta)\n",
    "y_onehot = one_hot(y_train)\n",
    "J = jacobian(x_train, y_onehot, P)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4c3ac848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conjugate Gradient Helper\n",
    "def H_dot(X, P, V):\n",
    "    \"\"\"\n",
    "    X: (n, d)\n",
    "    P: (n, c) --> doesn't contain probability of last class\n",
    "    V: (d * c)\n",
    "    \"\"\"\n",
    "    d = X.shape[1]\n",
    "    c = P.shape[1]\n",
    "    V = np.reshape(V, shape=(d, c))\n",
    "\n",
    "    Z = X @ V\n",
    "    W = P * (1 - P)\n",
    "    ZW = P * Z\n",
    "    Hv = X.T @ ZW\n",
    "    return np.reshape(Hv, d * c)\n",
    "\n",
    "def conj_grad(X, P, g, tol=1e-1):\n",
    "    d = X.shape[1]\n",
    "    c = P.shape[1]\n",
    "    res = g\n",
    "    p = g\n",
    "    k = 0\n",
    "    x = np.zeros(g.shape)\n",
    "    while k < g.shape[0]:\n",
    "        Ap =  H_dot(X, P, p)\n",
    "        rr = res @ res\n",
    "        alpha = (res @ res) / (p @ Ap + 1e-12)\n",
    "        x += alpha * p\n",
    "        res -= alpha * Ap\n",
    "\n",
    "        if np.linalg.norm(res) < tol:\n",
    "            break\n",
    "        beta = (res @ res) / (rr + 1e-12)\n",
    "        p = res + beta * p\n",
    "        k += 1\n",
    "    return np.reshape(x, shape=(d, c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5ddd62b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10 done.\n",
      "Epoch: 2/10 done.\n",
      "Epoch: 3/10 done.\n",
      "Epoch: 4/10 done.\n",
      "Epoch: 5/10 done.\n",
      "Epoch: 6/10 done.\n",
      "Epoch: 7/10 done.\n",
      "Epoch: 8/10 done.\n",
      "Epoch: 9/10 done.\n",
      "Epoch: 10/10 done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.64165751,  2.26464457],\n",
       "       [-1.54891715, -1.4441551 ],\n",
       "       [ 4.38765728,  1.24717958],\n",
       "       [ 3.00097108, -0.4692936 ],\n",
       "       [-2.62668675,  1.64162948]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train(X, Y, epochs=10):\n",
    "    C = np.unique(Y).size\n",
    "    d = X.shape[1]\n",
    "    y_onehot = one_hot(Y) # Remove last class\n",
    "    thetas = np.random.randn(X.shape[1], C-1)\n",
    "\n",
    "    # To Shuffle Batches:\n",
    "    gen = np.random.default_rng(SEED)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        idx = gen.permutation(len(X))\n",
    "        X_epoch = X[idx]\n",
    "        Y_epoch = y_onehot[idx]\n",
    "\n",
    "        P = Pr(X_epoch, thetas)\n",
    "        J = jacobian(X_epoch, Y_epoch, P)\n",
    "        J = np.reshape(J, shape=(d * (C-1)))\n",
    "        P = P[:, :-1]\n",
    "\n",
    "        thetas += conj_grad(X_epoch, P, J)\n",
    "        print(f\"Epoch: {epoch + 1}/{epochs} done.\")\n",
    "    return thetas\n",
    "train(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b3cb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LogisticRegression",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
